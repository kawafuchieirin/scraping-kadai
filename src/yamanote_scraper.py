#!/usr/bin/env python3
"""
å±±æ‰‹ç·šé…å»¶è¨¼æ˜æ›¸ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«
JRæ±æ—¥æœ¬ã®é…å»¶è¨¼æ˜æ›¸å±¥æ­´ãƒšãƒ¼ã‚¸ã‹ã‚‰1ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import os


class YamanoteDelayScraper:
    def __init__(self):
        self.base_url = "https://traininfo.jreast.co.jp/train_info/line.aspx?gid=1&lineid=yamanoteline"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
    def get_delay_history_data(self) -> List[Dict]:
        """
        å±±æ‰‹ç·šã®é…å»¶å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆéå»45æ—¥åˆ†ï¼‰
        
        Returns:
            é…å»¶ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        try:
            response = self.session.get(self.base_url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # é…å»¶å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
            delay_data = []
            
            # é…å»¶å±¥æ­´ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šï¼ˆè¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹å¯èƒ½æ€§ï¼‰
            tables = soup.find_all('table')
            
            for table in tables:
                rows = table.find_all('tr')
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‹ã‚‰æ™‚é–“å¸¯æƒ…å ±ã‚’å–å¾—
                header_row = None
                for row in rows:
                    cells = row.find_all(['th', 'td'])
                    header_text = ''.join([cell.get_text(strip=True) for cell in cells])
                    if 'å§‹ç™º' in header_text and 'çµ‚é›»' in header_text:
                        header_row = row
                        break
                
                if not header_row:
                    continue
                
                # æ™‚é–“å¸¯æƒ…å ±ã‚’æŠ½å‡º
                time_slots = []
                header_cells = header_row.find_all(['th', 'td'])
                for cell in header_cells[1:]:  # æœ€åˆã®ã‚»ãƒ«ï¼ˆæ—¥ä»˜åˆ—ï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    time_slot = cell.get_text(strip=True)
                    if time_slot and ('æ™‚' in time_slot or 'å§‹ç™º' in time_slot or 'çµ‚é›»' in time_slot):
                        time_slots.append(time_slot)
                
                # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†
                for row in rows:
                    if row == header_row:
                        continue
                        
                    cells = row.find_all(['td', 'th'])
                    if len(cells) < 2:
                        continue
                    
                    # æ—¥ä»˜ã‚’æŠ½å‡º
                    date_cell = cells[0]
                    date_text = date_cell.get_text(strip=True)
                    
                    # æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›ï¼ˆä¾‹ï¼šã€Œ7æœˆ3æ—¥ã€â†’ã€Œ2025-07-03ã€ï¼‰
                    parsed_date = self._parse_date(date_text)
                    if not parsed_date:
                        continue
                    
                    # å„æ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                    for i, time_slot in enumerate(time_slots):
                        if i + 1 < len(cells):
                            delay_cell = cells[i + 1]
                            delay_info = delay_cell.get_text(strip=True)
                            
                            # é…å»¶æ™‚é–“ã‚’æŠ½å‡º
                            delay_minutes = self._extract_delay_minutes(delay_info)
                            
                            delay_data.append({
                                'date': parsed_date,
                                'time_slot': time_slot,
                                'delay_info': delay_info,
                                'delay_minutes': delay_minutes,
                                'has_delay': delay_minutes > 0
                            })
            
            print(f"âœ… é…å»¶å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {len(delay_data)}ä»¶")
            return delay_data
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _parse_date(self, date_text: str) -> Optional[str]:
        """æ—¥ä»˜ãƒ†ã‚­ã‚¹ãƒˆã‚’YYYY-MM-DDå½¢å¼ã«å¤‰æ›"""
        try:
            # ç¾åœ¨ã®å¹´ã‚’å–å¾—
            current_year = datetime.now().year
            
            # ã€Œ7æœˆ3æ—¥ã€å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
            match = re.search(r'(\d{1,2})æœˆ(\d{1,2})æ—¥', date_text)
            if match:
                month = int(match.group(1))
                day = int(match.group(2))
                
                # å¹´ã‚’æ¨å®šï¼ˆç¾åœ¨ã®æœˆã‚ˆã‚Šæœªæ¥ã®æœˆãªã‚‰å‰å¹´ã¨ã™ã‚‹ï¼‰
                current_month = datetime.now().month
                if month > current_month:
                    year = current_year - 1
                else:
                    year = current_year
                
                return f"{year:04d}-{month:02d}-{day:02d}"
            
            return None
        except Exception:
            return None
    
    def _extract_delay_minutes(self, delay_info: str) -> int:
        """é…å»¶æƒ…å ±ã‹ã‚‰é…å»¶æ™‚é–“ï¼ˆåˆ†ï¼‰ã‚’æŠ½å‡º"""
        if not delay_info or delay_info == "-" or delay_info.strip() == "":
            return 0
        
        # ã€Œ61åˆ†ä»¥ä¸Šã€ã®å ´åˆ
        if '61åˆ†ä»¥ä¸Š' in delay_info or '60åˆ†ä»¥ä¸Š' in delay_info:
            return 61
            
        # ã€Œ10åˆ†ã€ã€Œ20åˆ†ã€ãªã©ã®æ•°å€¤ã‚’æŠ½å‡º
        match = re.search(r'(\d+)åˆ†', delay_info)
        if match:
            return int(match.group(1))
        
        # ã€Œé…å»¶ã€ã¨ã„ã†æ–‡å­—ãŒã‚ã‚Œã°æœ€å°é…å»¶ã¨ã—ã¦5åˆ†ã¨ã™ã‚‹
        if 'é…å»¶' in delay_info:
            return 5
            
        return 0
    
    def scrape_delay_history(self) -> pd.DataFrame:
        """
        å±±æ‰‹ç·šã®é…å»¶å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆéå»45æ—¥åˆ†ï¼‰
        
        Returns:
            é…å»¶ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        print("ğŸš† å±±æ‰‹ç·šã®é…å»¶å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—é–‹å§‹...")
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        all_data = self.get_delay_history_data()
        
        # æ›œæ—¥æƒ…å ±ã‚’è¿½åŠ 
        for data in all_data:
            try:
                date_obj = datetime.strptime(data['date'], '%Y-%m-%d')
                data['weekday'] = date_obj.strftime('%A')
                data['weekday_jp'] = self._get_japanese_weekday(date_obj.weekday())
            except Exception:
                data['weekday'] = 'Unknown'
                data['weekday_jp'] = 'ä¸æ˜'
        
        df = pd.DataFrame(all_data)
        
        if not df.empty:
            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’èª¿æ•´
            df['date'] = pd.to_datetime(df['date'])
            df['delay_minutes'] = df['delay_minutes'].astype(int)
            
            print(f"âœ… åˆè¨ˆ {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—å®Œäº†")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã‚’è¡¨ç¤º
            min_date = df['date'].min().strftime('%Y/%m/%d')
            max_date = df['date'].max().strftime('%Y/%m/%d')
            print(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        return df
    
    def _get_japanese_weekday(self, weekday: int) -> str:
        """æ›œæ—¥ç•ªå·ã‚’æ—¥æœ¬èªã«å¤‰æ›"""
        weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        return weekdays[weekday]
    
    def save_data(self, df: pd.DataFrame, filename: str = None) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'yamanote_delay_data_{timestamp}.csv'
        
        # dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        data_dir = 'data'
        os.makedirs(data_dir, exist_ok=True)
        filepath = os.path.join(data_dir, filename)
        
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        
        return filepath


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ä½¿ç”¨ä¾‹"""
    scraper = YamanoteDelayScraper()
    
    print("ğŸ“Š å±±æ‰‹ç·šã®é…å»¶å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»45æ—¥åˆ†ï¼‰ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™")
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    df = scraper.scrape_delay_history()
    
    if not df.empty:
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        filepath = scraper.save_data(df)
        
        # ç°¡å˜ãªçµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        print("\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
        print(f"ãƒ»ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
        print(f"ãƒ»é…å»¶ç™ºç”Ÿä»¶æ•°: {df['has_delay'].sum()}ä»¶")
        print(f"ãƒ»é…å»¶ç™ºç”Ÿç‡: {df['has_delay'].mean():.1%}")
        if df['has_delay'].sum() > 0:
            print(f"ãƒ»å¹³å‡é…å»¶æ™‚é–“: {df[df['has_delay']]['delay_minutes'].mean():.1f}åˆ†")
        
        print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: python src/analyze_data.py {filepath}")
    else:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚„ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()